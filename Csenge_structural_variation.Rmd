---
title: "Structural variation in purple sea urchins"
output:
  prettydoc::html_pretty:
    theme: cayman
fontsize: 18pt
---

# Using local PCA on the urchins


# 1. Input data processing
The pipeline will start from filtered bcf files, one for each of the 21 chromosomes.

Below is the steps that I followed to get from the raw sequence files to these bcf files.

## Mapped reads to the reference

### The reference genome

<https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_000002235.5/>

N50: 37.3 Mb

### The mapping algorythm

Input: List of read files (R1 and R2)

```{bash, eval = FALSE}
while read line ; do
        F1=$(cut -d ' ' -f1 <<< $line)
        F2=$(cut -d ' ' -f2 <<< $line)
        echo "$F1 -- $F2"
        FILE=$(mktemp)
        cat header.txt >> $FILE
        echo "spack load samtools@1.10" >> $FILE
        echo "spack load bwa@0.7.17" >> $FILE
        ref="/users/c/p/cpetak/WGS/reference_genome/GCF_000002235.5_Spur_5.0_genomic.fna"
        out_name=$(cut -d '.' -f1 <<< $F1)
        echo "bwa mem -t 1 -M $ref /users/c/p/cpetak/WGS/all_fastqs/$F1 /users/c/p/cpetak/WGS/all_fastqs/$F2 | samtools view -S -b > /users/c/p/cpetak/WGS/BWA_out/$out_name.bam" >> $FILE
        sbatch $FILE
        sleep 0.5
        rm $FILE
done < $1
```

The Burrows-Wheeler Alignment Tool (BWA) MEM algorithm was used for mapping the raw reads to the S. purpuratus reference genome (Spur ver. 5.0, scaffold N50 ∼37 Mbp). The average coverage for each individual was 6.42±0.78, with an average mapping rate of 81.6±0.01.

## Called variants for each chromosome across all individuals

Input:

-   21 chromosome names
-   list_of_files.txt, 140 lines, line 1: `/users/c/p/cpetak/WGS/BWA_out/BOD_18170X61_200925_A00421_0244_AHKML5DSXY_S81_L002_R1_001.rmdup.bam`

```{bash, eval = FALSE}
while read line ; do
	echo "$line"
	FILE=$(mktemp)
  cat header.txt >> $FILE
  ref="/users/c/p/cpetak/WGS/reference_genome/GCF_000002235.5_Spur_5.0_genomic.fna"
  echo "echo "${line}" " >> $FILE
  echo "bcftools mpileup -r $line -f $ref --bam-list list_of_files.txt | bcftools call -mv -Ob -o multi_bam_${line}.bcf" >> $FILE
  sbatch $FILE
  sleep 0.5
  rm $FILE
done < $1
```

## Filtering the bcf files

```{bash, eval = FALSE}
#!/bin/sh

mychr="NW_022145603.1"

# use bcftools to filter your chromosome. The output of this line will be a vcf file that we can look at

bcftools view -e 'QUAL <= 40 || DP < 560 || MQB < -3 || RPB < -3 || RPB > 3 || AN < 238' ~/mydata/str_data/multi_bam_${mychr}.bcf > ~/mydata/str_data/${mychr}_filtered.vcf

echo "Filtered bcf" # Some printing to keep track of progress

# Convert the filtered vcf into the bcf file type which is the type the R package will be expecting

bcftools view -Ob ~/mydata/str_data/${mychr}_filtered.vcf > ~/mydata/str_data/${mychr}_filtered.bcf

echo "Converted to bcf" # Some printing to keep track of progress

# Index the filtered bcf file. This will make the file more searchable by the algorythm reading it.

bcftools index ~/mydata/str_data/${mychr}_filtered.bcf
echo "Indexed bcf"
echo "Done!"
```

Output: bcf files in the `/users/c/p/cpetak/EG2023/structural_variation/backup/filtered_bcf_index ` directory.

# 2. Running local PCA
Local PCA is an R package, here is the GitHub page: <https://github.com/petrelharp/local_pca>. 

Installation:
```
install.packages("data.table")
devtools::install_github("petrelharp/local_pca/lostruct")
library(lostruct)
```

On the page, they provide an Rscript to show how to use the package. I copied this: 



-   Copy the R scripts over to your myscripts directory: `cp /netfiles/ecogen/structural_variation/run_lostruct.R ~/myscripts` and `cp /netfiles/ecogen/structural_variation/summarize_run.Rmd ~/myscripts`

## Let's look at the scripts

Type vim run_lostruct.R in the \~/myscripts directory.

## Run local PCA

-   IMPORTANT: make sure to remove the original unfiltered bcf file from your `~/mydata/str_data` directory, `rm multi_bam_mychromosome.bcf`, because the package will read all .bcf files in the directory that you give it and we only want to run the package on the filtered bcf file.

-   `tmux new -s run_localPCA`

-   `cd ~/mydata/str_data`. This way the results will automatically end up in this directory.

-   `Rscript ~/myscripts/run_lostruct.R -i ~/mydata/str_data -t snp -s 1000 -I /netfiles/ecogen/structural_variation/sample_info.tsv` We are running the Rscript with the "Rscript" command, just like we run the bash scripts with the "bash" command. -i specifies the input file location, -t specifies the way we are calculating the windows, which is based on SNPs for now. -s specifies the window size. -I specifies the location of the file I created to link the individual IDs in the bcf file with the 3 letter population name. This should take 15 minutes to an hour to run.

-   Once the script finishes, you should have a folder called lostruct_results in `~/mydata/str_data`. cd into lostruct_results. Then, cd into a folder called something like type_snp_size_1000_weights_none_jobid_166584 (will be called different for you). Type `ll`.

-   Output files:

    -   config.json -\> check with vim

    -   mds_coords.csv -\> wc -l -\> how many lines are there? each line corresponds to a window

    -   mychromosome.pca.csv -\> wc -l to check the number of rows and `awk -F',' '{print NF}' mychromosome.pca.csv | sort -nu | tail -n 1` to check the number of columns -\> should be 283. For each window (rows), PC1 and PC2 for each individual (140) -\> input variables for the MDS

    -   mychromosome.regions.csv -\> windows information (will be important later)

## Visualise results

NOTE: Make sure to change the `type_snp_size_1000_weights_none_jobid_166584` directory name everywhere in this tutorial to your directory name!

Now we'll use another script provided by the local PCA package to make an html with a series of plots.

-   `tmux attach-session -t run_localPCA`

-   cd into `~/mydata/str_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584/`

-   type `Rscript -e 'templater::render_template("~/myscripts/summarize_run.Rmd",output="~/mydata/str_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584/run_summary.html",change.rootdir=TRUE)'`

-   This should only take a few minutes. Once done, you should have new files in your `type_snp_size_1000_weights_none_jobid_166584` directory.

-   Open FileZilla on your computer. Move run_summary.html in the `~/mydata/str_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584` directory to your computer.

-   Find that file on your computer and open it in your favorite browser (e.g. Chrome).

## Select regions of interest

In order to be able to get the genomic regions corresponding to a specific corner in the MDS plot, we will need to modify the plotting script (summarize_run.Rmd) such that it writes a csv file with the coordinates.

-   `cd ~/myscripts`, `vim summarize_run.Rmd`, hit I to enter the insert mode.

-   Around line 195, the script creates a variable called corner.regions based on the mds corners. This variable contains a list of chromosome, start, end information for each window in each corners of the mds plot. So, all we need to do is insert a line `write.csv(corner.regions[[1]], "first_corner.csv", row.names=FALSE)` under the line 198 (`}`) to save the genomic regions in the first corner.

-   Hit `esc` and `:wq` to save your changes.

Repeat steps above to rerun the plotting.

-   `tmux attach-session -t run_localPCA`

-   cd into `~/mydata/str_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584/`

-   type `Rscript -e 'templater::render_template("~/myscripts/summarize_run.Rmd",output="~/mydata/str_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584/run_summary.html",change.rootdir=TRUE)'`

-   Now you should have a new file in `type_snp_size_1000_weights_none_jobid_166584` called `first_corner.csv`. Type `head first_corner.csv` to see the region information. NOTE: if you are not seeing the new file appear, you might have to delete the cache directory (`rm -r cache`) first, and then rerun the Rscript again.

## Do GO Enrichment for the selected corner

In order to get a list of genes that are present in the selected windows, we will use an annotation file from ncbi: <https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_000002235.5/>. GFF is a standard file format to store genomic annotation information in. I have already downloaded this file and moved it to `/netfiles/ecogen/structural_variation/`, and named it genome_annotation.gff. 

Copy this file into your directory, `cp /netfiles/ecogen/structural_variation/genome_annotation.gff ~/mydata/str_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584` Let's take a look!

To find an intersect between genes specified in the GFF file and coordinates in our first_corner.csv, we will use a package called bedtools. I have already installed this package for you. The intersectBed algorithm requires the first_corner.csv to be in a specific format (tab delimited, chromosome, start, end), so we'll need to modify it.

-   `cd ~/mydata/str_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584` if you are not there alread.

-   `head first_corner.csv` -\>

```{bash, eval = FALSE}
"chrom","start","end","pos"
"NW_022145602.1",227538,246919,237228.5
"NW_022145602.1",246921,249982,248451.5
"NW_022145602.1",250053,258244,254148.5
"NW_022145602.1",268365,272067,270216
"NW_022145602.1",283027,289393,286210
```

-   Remove 4th column: `cut -d, -f1-3 first_corner.csv > first_corner_formatted.csv` -\>

```{bash, eval = FALSE}
"chrom","start","end"
"NW_022145602.1",227538,246919
"NW_022145602.1",246921,249982
"NW_022145602.1",250053,258244
"NW_022145602.1",268365,272067
```

-   Remove "s: `sed -i 's/"//g' first_corner_formatted.csv`

-   Replace commas with tabs: `sed -i 's/,/\t/g' first_corner_formatted.csv` -\>

```{bash, eval = FALSE}
chrom	start	end
NW_022145602.1	227538	246919
NW_022145602.1	246921	249982
NW_022145602.1	250053	258244
NW_022145602.1	268365	272067
```

Now that we have the correct file format, let's run the intersectBed algorythm: `/netfiles/ecogen/structural_variation/bedtools2/bin/intersectBed -a first_corner_formatted.csv -b genome_annotation.gff -wa -wb > genes_first_corner.bed` Look at the genes_first_corner.bed file.

To extract the gene names: `sed -n "s/^.*gene=\(LOC[0-9]\+\).*$/\1/p" genes_first_corner.bed > gene_names_first_corner.txt`

You'll see that a lot of the gene names are repeated. To discard repeats, type: `sort gene_names_first_corner.txt | uniq > uni_gene_names_first_corner.txt`

Go to FileZilla on your computer and download this file (mydata/str_data/lostruct_results/type_snp_size_1000_weights_none_jobid_166584/uni_gene_names_first_corner.txt).

Now we can run a gene ontology analysis on these genes!

-   Open the txt file above, select all, copy (Ctrl C).

-   Go to: <https://geneontology.org/>, paste the LOC names into the window on the right.

-   Select Strongylocentrotus purpuratus (purple sea urchin) from the drop down menu instead of Homo sapiens. Click Launch.

-   If you don't get any significantly enriched biological processes, you can change the Annotation Data Set in the drop down menu and click Launch analysis. You can also play around with the Test type and the correction method. Don't worry if you still don't get anything, that is also a valid result!

Congrats! You are all done with this tutorial! :)

References:
